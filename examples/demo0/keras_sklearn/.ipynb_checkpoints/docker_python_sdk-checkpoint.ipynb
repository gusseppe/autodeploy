{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Image: 'autonomicbsc/workflow_api:latest', 'my-model:latest'>,\n",
       " <Image: 'autonomicbsc/workflow_master:latest'>,\n",
       " <Image: 'autonomicbsc/workflow_server:latest'>,\n",
       " <Image: 'autonomicbsc/workflow_worker:latest'>,\n",
       " <Image: 'autonomicbsc/cluster_hadoop_spark_python:latest'>,\n",
       " <Image: 'gusseppe/sparkhadoopcluster:latest'>,\n",
       " <Image: 'ubuntu:16.04'>,\n",
       " <Image: 'mlflow-docker-example-c11e2a0:latest'>,\n",
       " <Image: 'mlflow-docker-example:latest'>,\n",
       " <Image: 'continuumio/miniconda3:latest'>,\n",
       " <Image: 'drp:latest'>,\n",
       " <Image: 'ubuntu:latest'>,\n",
       " <Image: 'gusseppe/catnip:latest'>,\n",
       " <Image: 'jupyter/pyspark-notebook:latest'>,\n",
       " <Image: 'continuumio/miniconda:4.5.4'>,\n",
       " <Image: 'python:3-onbuild'>,\n",
       " <Image: 'prakhar1989/static-site:latest'>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.images.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Image: 'hello-world:latest', 'hello-world:linux'>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.images.pull('hello-world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4f7ee4f89dc59100bdc45d400407b54a7f1f4d6b540f3e78adebe01fd10a2e10'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "container = client.containers.run('hello-world', detach=True)\n",
    "container.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'created'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "container.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\nHello from Docker!\\nThis message shows that your installation appears to be working correctly.\\n\\nTo generate this message, Docker took the following steps:\\n 1. The Docker client contacted the Docker daemon.\\n 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\\n    (amd64)\\n 3. The Docker daemon created a new container from that image which runs the\\n    executable that produces the output you are currently reading.\\n 4. The Docker daemon streamed that output to the Docker client, which sent it\\n    to your terminal.\\n\\nTo try something more ambitious, you can run an Ubuntu container with:\\n $ docker run -it ubuntu bash\\n\\nShare images, automate workflows, and more with a free Docker ID:\\n https://hub.docker.com/\\n\\nFor more examples and ideas, visit:\\n https://docs.docker.com/get-started/\\n\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.containers.get(container.id).logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = client.containers.run('ubuntu', name='ubuntu_ctn', \n",
    "                                  command=\"/bin/bash\", tty=True,detach=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rewritting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = client.images.build(path=base_path, dockerfile=path, tag='worker_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/guess/Desktop/autodeploy/examples/workflow_sklearn'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.dirname(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image: 'hello-world:latest', 'worker_test:latest'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ImagesDeleted': None, 'SpaceReclaimed': 0}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# client.images.remove('worker_test')\n",
    "client.images.prune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ContainersDeleted': ['0f19c70aa3f842b4b51448b71a75d8a60d5823ab5b57c4fe244842b70b764ae4',\n",
       "  'f4efd3446d9f34a88e5bdbdf2540de49653946095d3c1ad382d5c209328fd86f',\n",
       "  '4f7ee4f89dc59100bdc45d400407b54a7f1f4d6b540f3e78adebe01fd10a2e10',\n",
       "  'b8a8cac4693dc09148bd0867718c1f465d5ac30018fc04a73053c74c07cdcac1',\n",
       "  'bb8762cf0f1234fad343fa5c5f544f59b6e669bef3103b8bccee361f11757318',\n",
       "  '152f8ee650b6edce423cc994bd35d6705defdf3160a0528a07df7eccfcd1dafb',\n",
       "  '986610c57ad2234eab304fe7a747629bd542aef5d4816b90502dc28997974650',\n",
       "  '6a87ac9cf9790564006949ddc6cbcf96e34b19062385f0b2d97bc6b83e6efb91',\n",
       "  '626d8db20490d874f753e069a18ffe1e2314f29d8e67d835b4155b7574b20b8d',\n",
       "  '1f560b17389da9f0c30e3a156950154a54db8d227943b8477959c19a842b6865'],\n",
       " 'SpaceReclaimed': 2075907165}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.containers.prune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Image: 'autonomicbsc/workflow_api:latest', 'my-model:latest'>,\n",
       " <Image: 'autonomicbsc/workflow_master:latest'>,\n",
       " <Image: 'autonomicbsc/workflow_server:latest'>,\n",
       " <Image: 'autonomicbsc/workflow_worker:latest'>,\n",
       " <Image: 'autonomicbsc/cluster_hadoop_spark_python:latest'>,\n",
       " <Image: 'gusseppe/sparkhadoopcluster:latest'>,\n",
       " <Image: 'ubuntu:16.04'>,\n",
       " <Image: 'mlflow-docker-example-c11e2a0:latest'>,\n",
       " <Image: 'mlflow-docker-example:latest'>,\n",
       " <Image: 'continuumio/miniconda3:latest'>,\n",
       " <Image: 'drp:latest'>,\n",
       " <Image: 'ubuntu:latest'>,\n",
       " <Image: 'gusseppe/catnip:latest'>,\n",
       " <Image: 'jupyter/pyspark-notebook:latest'>,\n",
       " <Image: 'hello-world:latest', 'hello-world:linux'>,\n",
       " <Image: 'continuumio/miniconda:4.5.4'>,\n",
       " <Image: 'python:3-onbuild'>,\n",
       " <Image: 'prakhar1989/static-site:latest'>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.images.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.containers.list()[0].stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.images.remove('fce289e99eb9', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing setup.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile setup.py\n",
    "\n",
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Author: Gusseppe Bravo <gbravor@uni.pe>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import docker\n",
    "import errno\n",
    "import os\n",
    "\n",
    "client = docker.from_env()\n",
    "\n",
    "class Setup:\n",
    "    def __init__(self,\n",
    "                 single_file,\n",
    "                 master_file=None,\n",
    "                 worker_file=None,\n",
    "                 n_workers=2,\n",
    "                 type_app='single'):\n",
    "        \"\"\"\n",
    "        Example:\n",
    "            setup = Setup(single_file='/home/user/Dockerfile')\n",
    "\n",
    "        Parameters:\n",
    "            single_file (str): Path to a Dockerfile, single mode.\n",
    "            master_file (str): Path to a Dockerfile, cluster mode.\n",
    "            worker_file (str): Path to a Dockerfile, cluster mode.\n",
    "            n_workers (int): if type_app=='cluster' then it means the \n",
    "                             number of slaves (workers)\n",
    "            type_app (str): Type of platform.\n",
    "        \n",
    "        \"\"\"    \n",
    "        self.type_app = type_app\n",
    "        self.single_file = single_file\n",
    "        self.master_file = master_file\n",
    "        self.worker_file = worker_file\n",
    "        self.n_workers = n_workers\n",
    "        self.tag_image = None\n",
    "        self.image = None\n",
    "        self.containers = None\n",
    "    \n",
    "    def pipeline(self):\n",
    "        self.build()\n",
    "        self.run()\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def build(self, name='app'):\n",
    "        \"\"\"\n",
    "        Build a platform with Docker images.\n",
    "        \n",
    "        Parameters:\n",
    "            name (str): Prefix of a Docker image.\n",
    "        Returns:\n",
    "            image (object): Docker image.\n",
    "        \"\"\"\n",
    "        if self.type_app == 'single':\n",
    "            base_path = os.path.dirname(self.single_file)\n",
    "            self.tag_image = name+'_'+self.type_app\n",
    "            image = client.images.build(path=base_path, \n",
    "                                        dockerfile=self.single_file, \n",
    "                                        tag=self.tag_image)\n",
    "            self.image = image\n",
    "            \n",
    "            return image\n",
    "        \n",
    "    def run(self, name='app'):\n",
    "        \"\"\"\n",
    "        Run a platform with Docker containers.\n",
    "        \n",
    "        Parameters:\n",
    "            name (str): Prefix of a Docker container.\n",
    "        Returns:\n",
    "            image (object): Docker container.\n",
    "        \"\"\"\n",
    "        if self.type_app == 'single':\n",
    "            ports = {'8001/tcp': 8001}  \n",
    "            host_path = os.path.join(os.path.abspath('.'), 'app_single')\n",
    "            try:\n",
    "                print(host_path)\n",
    "                os.makedirs(host_path)\n",
    "            except OSError as exception:\n",
    "                if exception.errno != errno.EEXIST:\n",
    "                    raise\n",
    "            container_path = '/root/project'\n",
    "            volumen = {host_path: {'bind': container_path, 'mode': 'rw'}}\n",
    "            container = client.containers.run(self.tag_image, name=self.tag_image, \n",
    "                                              tty=True, detach=True,\n",
    "                                              volumes=volumen, ports=ports)\n",
    "            cmd = \"\"\"\n",
    "            mlflow server \\\n",
    "                --backend-store-uri ./mlruns \\\n",
    "                --host 0.0.0.0 -p 8001\n",
    "            \"\"\"\n",
    "            container.exec_run(cmd=cmd, detach=True)\n",
    "        \n",
    "            self.containers = [container]\n",
    "            \n",
    "            return container\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Setup at 0x7f5dd9bb2908>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_file = os.path.join(os.path.abspath('.'), 'Dockerfile.app')\n",
    "# single_file = '/home/guess/Desktop/autodeploy/examples/workflow_sklearn/Dockerfile'\n",
    "s = Setup(single_file)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Image: 'app_single:latest'>, <itertools._tee at 0x7f5dd181b108>)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = s.build()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/guess/Desktop/autodeploy/examples/workflow_sklearn/app_single\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Container: 5ae8d54e65>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "container = s.run()\n",
    "container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'app_single'"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "container.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExecResult(exit_code=0, output=b'MLproject\\ngathering.py\\ngenerate.py\\nmain.py\\nmlruns\\nmodeling.py\\npreprocessing.py\\nraw_data.csv\\ntest.py\\n')"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "container.exec_run(cmd='ls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExecResult(exit_code=0, output=b'06-Aug-19 21:21:21 - Dataset was generated successfully and saved in ./raw_data.csv \\n        x_1       x_2       x_3       x_4  y\\n0 -1.887365 -1.145569  0.839676 -2.008856  0\\n1 -0.182668 -0.122267  0.082513 -0.205466  0\\n2 -0.731595  0.655904  0.205311  0.287141  0\\n3 -0.774965  0.744027  0.212103  0.351875  0\\n4 -1.339423 -1.042463  0.620971 -1.647999  0\\n')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "container.exec_run(cmd='python generate.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExecResult(exit_code=0, output=b'1.1.0\\nexp_name = single_20190806-212628 | exp_id = 1\\n        x_1       x_2       x_3       x_4  y\\n0 -1.887365 -1.145569  0.839676 -2.008856  0\\n1 -0.182668 -0.122267  0.082513 -0.205466  0\\n2 -0.731595  0.655904  0.205311  0.287141  0\\n3 -0.774965  0.744027  0.212103  0.351875  0\\n4 -1.339423 -1.042463  0.620971 -1.647999  0\\n')"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "container.exec_run(cmd='python gathering.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matching run has been found.\n",
      "2019/08/07 00:19:07 INFO mlflow.projects: === Created directory /tmp/tmpymcidd79 for downloading remote URIs passed to arguments of type 'path' ===\n",
      "2019/08/07 00:19:07 INFO mlflow.projects: === Running command 'python gathering.py' in run with ID '6b76f51b69424ed5bd47f92d2b24b1b3' === \n",
      "1.1.0\n",
      "        x_1       x_2       x_3       x_4  y\n",
      "0 -1.887365 -1.145569  0.839676 -2.008856  0\n",
      "1 -0.182668 -0.122267  0.082513 -0.205466  0\n",
      "2 -0.731595  0.655904  0.205311  0.287141  0\n",
      "3 -0.774965  0.744027  0.212103  0.351875  0\n",
      "4 -1.339423 -1.042463  0.620971 -1.647999  0\n",
      "2019/08/07 00:19:08 INFO mlflow.projects: === Run (ID '6b76f51b69424ed5bd47f92d2b24b1b3') succeeded ===\n",
      "No matching run has been found.\n",
      "2019/08/07 00:19:08 INFO mlflow.projects: === Created directory /tmp/tmpqqiu1cue for downloading remote URIs passed to arguments of type 'path' ===\n",
      "2019/08/07 00:19:08 INFO mlflow.projects: === Running command 'python preprocessing.py' in run with ID 'd6b697c5d03745cc814d174b56334172' === \n",
      "2019/08/07 00:19:09 INFO mlflow.projects: === Run (ID 'd6b697c5d03745cc814d174b56334172') succeeded ===\n",
      "No matching run has been found.\n",
      "2019/08/07 00:19:09 INFO mlflow.projects: === Created directory /tmp/tmpb__1bl_v for downloading remote URIs passed to arguments of type 'path' ===\n",
      "2019/08/07 00:19:09 INFO mlflow.projects: === Running command 'python modeling.py --source file:///root/project/mlruns/0/d6b697c5d03745cc814d174b56334172/artifacts/preprocessed_data.csv' in run with ID '4c6197e43eca4cc2bace210fff04aa1c' === \n",
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py:15: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/nest.py:1286: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  _pywrap_tensorflow.RegisterType(\"Mapping\", _collections.Mapping)\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/object_identity.py:61: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  class ObjectIdentityDictionary(collections.MutableMapping):\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/keras/callbacks.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0807 00:19:11.111134 140342451709312 deprecation_wrapper.py:119] From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0807 00:19:11.120068 140342451709312 deprecation_wrapper.py:119] From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0807 00:19:11.121165 140342451709312 deprecation_wrapper.py:119] From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "W0807 00:19:11.138386 140342451709312 deprecation_wrapper.py:119] From /opt/conda/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0807 00:19:11.152154 140342451709312 deprecation_wrapper.py:119] From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0807 00:19:11.155107 140342451709312 deprecation.py:323] From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0807 00:19:11.274626 140342451709312 deprecation_wrapper.py:119] From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "2019-08-07 00:19:11.356257: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-08-07 00:19:11.380869: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2808000000 Hz\n",
      "2019-08-07 00:19:11.382008: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5622df9a4d20 executing computations on platform Host. Devices:\n",
      "2019-08-07 00:19:11.382053: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-08-07 00:19:11.446114: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "Train on 6400 samples, validate on 1600 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.6724 - acc: 0.7630 - val_loss: 0.6318 - val_acc: 0.8906\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.5659 - acc: 0.8836 - val_loss: 0.4800 - val_acc: 0.8888\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.4177 - acc: 0.8805 - val_loss: 0.3532 - val_acc: 0.8894\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.3307 - acc: 0.8841 - val_loss: 0.3007 - val_acc: 0.8919\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.2941 - acc: 0.8891 - val_loss: 0.2789 - val_acc: 0.8962\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.2754 - acc: 0.8969 - val_loss: 0.2663 - val_acc: 0.9038\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.2622 - acc: 0.9038 - val_loss: 0.2567 - val_acc: 0.9119\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.2514 - acc: 0.9122 - val_loss: 0.2486 - val_acc: 0.9163\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.2422 - acc: 0.9167 - val_loss: 0.2416 - val_acc: 0.9200\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.2344 - acc: 0.9216 - val_loss: 0.2357 - val_acc: 0.9225\n",
      "The model had a ACC on the test set of 0.922\n",
      "2019/08/07 00:19:12 INFO mlflow.projects: === Run (ID '4c6197e43eca4cc2bace210fff04aa1c') succeeded ===\n",
      "Launching new run for entrypoint=gathering and parameters={}\n",
      "Launching new run for entrypoint=preprocessing and parameters={}\n",
      "Launching new run for entrypoint=modeling and parameters={'source': 'file:///root/project/mlruns/0/d6b697c5d03745cc814d174b56334172/artifacts/preprocessed_data.csv'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = container.exec_run(cmd='python main.py')\n",
    "print(result.output.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing deploy.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile deploy.py\n",
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Author: Gusseppe Bravo <gbravor@uni.pe>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import subprocess\n",
    "import docker\n",
    "import errno\n",
    "\n",
    "client = docker.from_env()\n",
    "\n",
    "class Deploy:\n",
    "    def __init__(self,\n",
    "                 setup, workflow=None):\n",
    "        \"\"\"\n",
    "        Example:\n",
    "            deploy = Deploy(setup, workflow)\n",
    "\n",
    "        Parameters:\n",
    "            container (object): Container, single mode.\n",
    "            workflow (dict): Dict of python files.\n",
    "        \n",
    "        \"\"\"    \n",
    "        self.setup = setup\n",
    "        self.container = setup.containers[0]\n",
    "        self.workflow = workflow\n",
    "    \n",
    "    def pipeline(self):\n",
    "        self.run_workflow()\n",
    "        self.deploy()\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def run_workflow(self):\n",
    "        \"\"\"\n",
    "        Build a platform with Docker images.\n",
    "        \n",
    "        Parameters:\n",
    "            name (str): Prefix of a Docker image.\n",
    "        Returns:\n",
    "            image (object): Docker image.\n",
    "        \"\"\"\n",
    "        if self.setup.type_app == 'single':\n",
    "            result = self.container.exec_run(cmd='python main.py')\n",
    "            return result.output.decode(\"utf-8\")\n",
    "        \n",
    "    def deploy(self, name='app'):\n",
    "        \"\"\"\n",
    "        Run a platform with Docker containers.\n",
    "        \n",
    "        Parameters:\n",
    "            name (str): Prefix of a Docker container.\n",
    "        Returns:\n",
    "            image (object): Docker container.\n",
    "        \"\"\"\n",
    "        if self.setup.type_app == 'single':\n",
    "            cmd_build = 'mlflow models build-docker -m ./app_single/models -n app_single_api'\n",
    "            output_build = subprocess.call(cmd_build.split())\n",
    "            \n",
    "            cmd_run = 'docker run -p 5001:8080 app_single_api'\n",
    "            output_run = subprocess.call(cmd_run.split())\n",
    "                       \n",
    "            return output_build, output_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mlflow',\n",
       " 'models',\n",
       " 'build-docker',\n",
       " '-m',\n",
       " './app_single/models',\n",
       " '-n',\n",
       " '\"app_single_api\"']"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd_build = 'mlflow models build-docker -m ./app_single/models -n \"app_single_api\"'\n",
    "cmd_build.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Deploy at 0x7f5dd167b6a0>"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = Deploy(setup=s)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_workflow = d.run_workflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "output_build, output_run = d.deploy()\n",
    "print(output_build)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing track.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile track.py\n",
    "\n",
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Author: Gusseppe Bravo <gbravor@uni.pe>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import subprocess\n",
    "import docker\n",
    "import errno\n",
    "import requests \n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "\n",
    "client = docker.from_env()\n",
    "\n",
    "class Track:\n",
    "    def __init__(self, \n",
    "                 api_name='app_single_api',\n",
    "                 port=5001):\n",
    "        \"\"\"\n",
    "        Example:\n",
    "            deploy = Deploy(setup, workflow)\n",
    "\n",
    "        Parameters:\n",
    "            container (object): Container, single mode.\n",
    "            workflow (dict): Dict of python files.\n",
    "        \n",
    "        \"\"\"    \n",
    "        self.api_name = api_name\n",
    "        self.port = port\n",
    "\n",
    "    \n",
    "    def pipeline(self):\n",
    "        self.predict()\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, sample_input):\n",
    "        \"\"\"\n",
    "        Build a platform with Docker images.\n",
    "        \n",
    "        Parameters:\n",
    "            name (str): Prefix of a Docker image.\n",
    "        Returns:\n",
    "            image (object): Docker image.\n",
    "        \"\"\"\n",
    "        url = f'http://localhost:{self.port}/invocations'\n",
    "\n",
    "        start = time.time()\n",
    "#         for _ in range(n_requests):\n",
    "        response = requests.post( \n",
    "                     url=url, data=json.dumps(sample_input), \n",
    "                      headers={\"Content-type\": \"application/json; format=pandas-split\"})\n",
    "        response_json = json.loads(response.text)\n",
    "            #print(response_json)\n",
    "\n",
    "        end = time.time()\n",
    "        print(f'Container in port: {self.port}')\n",
    "        print(f'Time elapsed: {end-start}')\n",
    "        \n",
    "        return response_json\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container in port: 5001\n",
      "Time elapsed: 0.0714712142944336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'0': 0.9965819716453552}, {'0': 0.06053623557090759}]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_input = { \n",
    "        \"columns\": [ \n",
    "            \"x_1\", \n",
    "            \"x_2\", \n",
    "            \"x_3\", \n",
    "            \"x_4\", \n",
    "        ], \n",
    "        \"data\": [ \n",
    "            [1.646629,  0.811971, -0.712092,  1.570961],\n",
    "        [-0.989919,  0.987401, 0.266892,  0.485329]  \n",
    "        ] \n",
    "}  \n",
    "\n",
    "t = Track()\n",
    "r = t.predict(sample_input)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RunInfo' object has no attribute 'source_version'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-163-bdbfaeb494ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactive_run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#         os.environ['SPARK_CONF_DIR'] = os.path.abspath('.')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msource_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactive_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'RunInfo' object has no attribute 'source_version'"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "ss = None\n",
    "with mlflow.start_run() as active_run:\n",
    "    ss = active_run\n",
    "#         os.environ['SPARK_CONF_DIR'] = os.path.abspath('.')\n",
    "    source_version = active_run.info.source_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow import models\n",
    "\n",
    "models.FlavorBackend(config=)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
