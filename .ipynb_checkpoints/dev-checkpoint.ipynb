{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Development new ideas\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters python file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker-compose.yml\t      gathered.csv  models\t\t   X_test.csv\n",
      "Dockerfile_gathering\t      gathering.py  preprocessed_data.csv  X_train.csv\n",
      "Dockerfile_modeling\t      leaf.csv\t    preprocessing.py\t   y_test.csv\n",
      "Dockerfile_preprocessing      main.py\t    req_gathering.txt\t   y_train.csv\n",
      "Dockerfile_tracker_workflow1  mlruns\t    req_modeling.txt\n",
      "Dockerfile_tracker_workflow2  modeling.py   req_preprocessing.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/home/guess/Desktop/scanflow/examples/demo2/data-science/workflow')\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'--raw_data_path ./leaf.csv'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'raw_data_path': './leaf.csv',\n",
    "          'percentage': 0.7}\n",
    "params = {'raw_data_path': './leaf.csv'}\n",
    "\n",
    "def format_parameters(params):\n",
    "    list_params = list()\n",
    "    for k, v in params.items():\n",
    "        list_params.append(f\"--{k} {v}\")\n",
    "    return ' '.join(list_params)\n",
    "\n",
    "\n",
    "format_parameters(params)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python /home/guess/Desktop/scanflow/examples/demo2/data-science/workflow/gathering.py --raw_data_path ./leaf.csv --percentage 0.7'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd_build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   species  specimen_number  eccentricity  ...  third_moment  uniformity  entropy\n",
      "0        1                1       0.72694  ...      0.005232    0.000275  1.17560\n",
      "1        1                2       0.74173  ...      0.002708    0.000075  0.69659\n",
      "2        1                3       0.76722  ...      0.000921    0.000038  0.44348\n",
      "3        1                4       0.73797  ...      0.001154    0.000066  0.58785\n",
      "4        1                5       0.82301  ...      0.000560    0.000024  0.34214\n",
      "\n",
      "[5 rows x 16 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "app_dir = '/home/guess/Desktop/scanflow/examples/demo2/data-science/workflow/gathering.py'\n",
    "\n",
    "parameters = format_parameters(params)  \n",
    "cmd_build = f'python {app_dir} {parameters}'\n",
    "logs = subprocess.check_output(cmd_build.split())\n",
    "print(logs.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.33 ms, sys: 0 ns, total: 3.33 ms\n",
      "Wall time: 3.37 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.144517</td>\n",
       "      <td>0.188910</td>\n",
       "      <td>0.491861</td>\n",
       "      <td>0.660352</td>\n",
       "      <td>0.191867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.796768</td>\n",
       "      <td>0.461580</td>\n",
       "      <td>0.444235</td>\n",
       "      <td>0.131212</td>\n",
       "      <td>0.385720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.610776</td>\n",
       "      <td>0.932146</td>\n",
       "      <td>0.035473</td>\n",
       "      <td>0.545145</td>\n",
       "      <td>0.325802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          a         b         c         d         e\n",
       "0  0.144517  0.188910  0.491861  0.660352  0.191867\n",
       "1  0.796768  0.461580  0.444235  0.131212  0.385720\n",
       "2  0.610776  0.932146  0.035473  0.545145  0.325802"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas_profiling.config import config as config\n",
    "from pandas_profiling.model import describe\n",
    "import pandas_profiling\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    np.random.rand(100, 5),\n",
    "    columns=['a', 'b', 'c', 'd', 'e']\n",
    ")\n",
    "\n",
    "df.head(3)\n",
    "#profile = df.profile_report()\n",
    "\n",
    "# config.config['pool_size'] = 4\n",
    "# config.config['check_correlation_pearson'] = False\n",
    "# print(list(config.config.items()))\n",
    "# desc_df = pandas_profiling.describe_df(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictions = ''\n",
    "%store -r predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-1.887365</td>\n",
       "      <td>-1.145500</td>\n",
       "      <td>0.839670</td>\n",
       "      <td>-2.008855</td>\n",
       "      <td>0.024753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.989919</td>\n",
       "      <td>0.987401</td>\n",
       "      <td>0.266892</td>\n",
       "      <td>0.485329</td>\n",
       "      <td>0.060526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        x_1       x_2       x_3       x_4      pred\n",
       "0 -1.887365 -1.145500  0.839670 -2.008855  0.024753\n",
       "1 -0.989919  0.987401  0.266892  0.485329  0.060526"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sample_input = { \n",
    "        \"columns\": [ \n",
    "            \"x_1\", \n",
    "            \"x_2\", \n",
    "            \"x_3\", \n",
    "            \"x_4\", \n",
    "        ], \n",
    "        \"data\": [ \n",
    "            [-1.8873649,-1.1455,0.83967,-2.008855],\n",
    "            [-0.989919,  0.987401, 0.266892,  0.485329]  \n",
    "        ] \n",
    "}   \n",
    "\n",
    "df_pred = pd.DataFrame(sample_input['data'], \n",
    "                       columns=sample_input['columns'])\n",
    "preds = [d['0'] for d in predictions]\n",
    "df_pred['pred'] = preds\n",
    "df_pred\n",
    "\n",
    "# preds\n",
    "\n",
    "# df_pred = pd.DataFrame(predictions)\n",
    "# df_pred.columns = ['predictions']\n",
    "# df_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pearson':           a         b         c         d         e\n",
       " a  1.000000 -0.209623  0.027904 -0.159071  0.167123\n",
       " b -0.209623  1.000000  0.050510 -0.030962  0.035198\n",
       " c  0.027904  0.050510  1.000000 -0.190184  0.023870\n",
       " d -0.159071 -0.030962 -0.190184  1.000000 -0.140414\n",
       " e  0.167123  0.035198  0.023870 -0.140414  1.000000,\n",
       " 'spearman':           a         b         c         d         e\n",
       " a  1.000000 -0.209781  0.015770 -0.158224  0.183102\n",
       " b -0.209781  1.000000  0.050117 -0.036280  0.040216\n",
       " c  0.015770  0.050117  1.000000 -0.173513  0.021338\n",
       " d -0.158224 -0.036280 -0.173513  1.000000 -0.123684\n",
       " e  0.183102  0.040216  0.021338 -0.123684  1.000000,\n",
       " 'kendall':           a         b         c         d         e\n",
       " a  1.000000 -0.135354  0.018182 -0.102626  0.119596\n",
       " b -0.135354  1.000000  0.025455 -0.026667  0.030707\n",
       " c  0.018182  0.025455  1.000000 -0.121212  0.019394\n",
       " d -0.102626 -0.026667 -0.121212  1.000000 -0.106263\n",
       " e  0.119596  0.030707  0.019394 -0.106263  1.000000,\n",
       " 'phi_k': var2         a         b         c         d        e\n",
       " var1                                                 \n",
       " a     1.000000  0.362056  0.000000  0.047395  0.00000\n",
       " b     0.362056  1.000000  0.000000  0.000000  0.00000\n",
       " c     0.000000  0.000000  1.000000  0.443129  0.00000\n",
       " d     0.047395  0.000000  0.443129  1.000000  0.59253\n",
       " e     0.000000  0.000000  0.000000  0.592530  1.00000}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# desc_df['table']\n",
    "# desc_df['variables'].keys()\n",
    "# desc_df['correlations']\n",
    "# list(desc\n",
    "#_df.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## pyyml\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version: '3'\n",
      "services:\n",
      "  vote:\n",
      "    build: ./vote\n",
      "    command: python app.py\n",
      "    volumes: ['./vote:/app']\n",
      "    ports: ['5000:80']\n",
      "    networks: [front-tier, back-tier]\n",
      "  result:\n",
      "    build: ./result\n",
      "    command: nodemon server.js\n",
      "    volumes: ['./result:/app']\n",
      "    ports: ['5001:80', '5858:5858']\n",
      "    networks: [front-tier, back-tier]\n",
      "  worker:\n",
      "    build: {context: ./worker}\n",
      "    depends_on: [redis, db]\n",
      "    networks: [back-tier]\n",
      "  redis:\n",
      "    image: redis:alpine\n",
      "    container_name: redis\n",
      "    ports: ['6379']\n",
      "    networks: [back-tier]\n",
      "  db:\n",
      "    image: postgres:9.4\n",
      "    container_name: db\n",
      "    volumes: ['db-data:/var/lib/postgresql/data']\n",
      "    networks: [back-tier]\n",
      "volumes: {db-data: null}\n",
      "networks: {front-tier: null, back-tier: null}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import oyaml as yaml\n",
    "\n",
    "with open('docker-compose.yml') as f:\n",
    "    data = yaml.load(f)\n",
    "    \n",
    "# for k, v in data.items():\n",
    "#   print(k, '->', v)\n",
    "\n",
    "\n",
    "print(yaml.dump(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'version': '3',\n",
       " 'services': {'vote': {'build': './vote',\n",
       "   'command': 'python app.py',\n",
       "   'volumes': ['./vote:/app'],\n",
       "   'ports': ['5000:80'],\n",
       "   'networks': ['front-tier', 'back-tier']},\n",
       "  'result': {'build': './result',\n",
       "   'command': 'nodemon server.js',\n",
       "   'volumes': ['./result:/app'],\n",
       "   'ports': ['5001:80', '5858:5858'],\n",
       "   'networks': ['front-tier', 'back-tier']},\n",
       "  'worker': {'build': {'context': './worker'},\n",
       "   'depends_on': ['redis', 'db'],\n",
       "   'networks': ['back-tier']},\n",
       "  'redis': {'image': 'redis:alpine',\n",
       "   'container_name': 'redis',\n",
       "   'ports': ['6379'],\n",
       "   'networks': ['back-tier']},\n",
       "  'db': {'image': 'postgres:9.4',\n",
       "   'container_name': 'db',\n",
       "   'volumes': ['db-data:/var/lib/postgresql/data'],\n",
       "   'networks': ['back-tier']}},\n",
       " 'volumes': {'db-data': None},\n",
       " 'networks': {'front-tier': None, 'back-tier': None}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test-compose.yaml', 'w') as f:\n",
    "    yaml.dump(data, f, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Each environment for each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'workflow1',\n",
       "  'workflow': [{'name': 'gathering',\n",
       "    'file': 'gathering.py',\n",
       "    'dockerfile': 'Dockerfile_gathering'},\n",
       "   {'name': 'preprocessing',\n",
       "    'file': 'preprocessing.py',\n",
       "    'requirements': 'req_preprocessing.txt'},\n",
       "   {'name': 'main1', 'file': 'main1.py'}],\n",
       "  'tracker': True},\n",
       " {'name': 'workflow2',\n",
       "  'workflow': [{'name': 'modeling',\n",
       "    'file': 'modeling.py',\n",
       "    'requirements': 'req_modeling.txt'},\n",
       "   {'name': 'main2', 'file': 'main2.py'}],\n",
       "  'tracker': True}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import oyaml as yaml\n",
    "\n",
    "from scanflow.setup import setup\n",
    "\n",
    "# App folder\n",
    "app_dir = '/home/guess/Desktop/scanflow/examples/leaf4'\n",
    "\n",
    "# Workflows\n",
    "workflow1 = [\n",
    "    {'name': 'gathering', 'file': 'gathering.py', \n",
    "            'dockerfile': 'Dockerfile_gathering'}, # Provides a dockerfile\n",
    "    \n",
    "    {'name': 'preprocessing', 'file': 'preprocessing.py', \n",
    "            'requirements': 'req_preprocessing.txt'}, # Convert requirements.txt to dockerfile\n",
    "    {'name': 'main1', 'file': 'main1.py'},\n",
    "]\n",
    "workflow2 = [\n",
    "    {'name': 'modeling', 'file': 'modeling.py', \n",
    "            'requirements': 'req_modeling.txt'}, # Convert requirements.txt to dockerfile\n",
    "    \n",
    "    {'name': 'main2', 'file': 'main2.py'},\n",
    "    \n",
    "]\n",
    "workflows = [\n",
    "    {'name': 'workflow1', 'workflow': workflow1, 'tracker': True},\n",
    "    {'name': 'workflow2', 'workflow': workflow2, 'tracker': True}\n",
    "            \n",
    "]\n",
    "\n",
    "# workflow = {'gathering': 'gathering.py',\n",
    "#             'preprocessing': 'preprocessing.py',\n",
    "#             'modeling': 'modeling.py',\n",
    "#             'main': 'main.py'}\n",
    "\n",
    "# workflower = setup.Setup(app_dir, workflow)\n",
    "\n",
    "# workflower.create_env(name='app')\n",
    "\n",
    "# workflower\n",
    "workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'workflow1',\n",
       " 'entry_points': {'gathering': {'command': 'gathering.py'},\n",
       "  'preprocessing': {'command': 'preprocessing.py'},\n",
       "  'main1': {'command': 'main1.py'}}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "       \n",
    "def mlproject_template(workflow, name='workflow'):\n",
    "\n",
    "    mlproject = {'name': name, \n",
    "                 'entry_points': { \n",
    "                     wflow['name']: {'command': wflow['file']} for wflow in workflow\n",
    "                  }       \n",
    "                }\n",
    "    \n",
    "    \n",
    "    return mlproject\n",
    "\n",
    "#     return template\n",
    "# print(yaml.dump(mlproject))\n",
    "\n",
    "mlproject = mlproject_template(workflows[0]['workflow'], name=workflows[0]['name'])\n",
    "mlproject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test-mlproject.yaml', 'w') as f:\n",
    "    yaml.dump(mlproject, f, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Docker compose\n",
    "\n",
    "Goal: After all the setting,generate a docker compose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas\n",
    "\n",
    "Once we have the docker compose file it can ported to Docker Swarm:\n",
    "\n",
    "- docker stack deploy --compose-file docker-stack.yml app_name\n",
    "https://github.com/docker/labs/blob/master/beginner/chapters/votingapp.md\n",
    "\n",
    "And also to Kubernets:\n",
    "\n",
    "- kompose convert\n",
    "- kubectl apply -f frontend-service.yaml,redis-master-service.yaml, ...\n",
    "https://kubernetes.io/docs/tasks/configure-pod-container/translate-compose-kubernetes/\n",
    "\n",
    "Mlflow release Model Registry:\n",
    "\n",
    "- https://mlflow.org/docs/latest/registry.html\n",
    "\n",
    "New Checker based on autoencoders:\n",
    "\n",
    "- This new checker take into account realtime prediction (before was batch).\n",
    "- Because i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container: 0004cd9143>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import docker\n",
    "client = docker.from_env()\n",
    "name = 'tracker_workflow1'\n",
    "# name = 'modeling'\n",
    "container_from_env = client.containers.get(name)\n",
    "container_from_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'exited'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "container_from_env.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "\n",
    "port = 5000\n",
    "\n",
    "template = dedent(f'''\n",
    "            FROM continuumio/miniconda3\n",
    "            LABEL maintainer='scanflow'\n",
    "\n",
    "            ENV MLFLOW_HOME  /mlflow\n",
    "            ENV MLFLOW_PORT  {port}\n",
    "            ENV MLFLOW_HOST  0.0.0.0\n",
    "            ENV MLFLOW_ARTIFACT  /mlflow/artifact\n",
    "            ENV MLFLOW_BACKEND  /mlflow/backend\n",
    "\n",
    "            RUN pip install mlflow\n",
    "            RUN mkdir $MLFLOW_HOME\n",
    "            RUN mkdir -p $MLFLOW_ARTIFACT\n",
    "            RUN mkdir -p $MLFLOW_BACKEND\n",
    "\n",
    "            CMD mlflow server \\\n",
    "            --backend-store-uri $MLFLOW_BACKEND \\ \n",
    "            --default-artifact-root $MLFLOW_ARTIFACT \\\n",
    "            --host 0.0.0.0 -p {port}\n",
    "            \n",
    "''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FROM continuumio/miniconda3\n",
      "LABEL maintainer='scanflow'\n",
      "\n",
      "ENV MLFLOW_HOME  /mlflow\n",
      "ENV MLFLOW_HOST  0.0.0.0\n",
      "ENV MLFLOW_PORT  8001\n",
      "ENV MLFLOW_BACKEND  /mlflow/backend\n",
      "ENV MLFLOW_ARTIFACT  /mlflow/artifact\n",
      "\n",
      "RUN pip install mlflow\n",
      "RUN mkdir $MLFLOW_HOME\n",
      "RUN mkdir -p $MLFLOW_ARTIFACT\n",
      "RUN mkdir -p $MLFLOW_BACKEND\n",
      "\n",
      "CMD mlflow server                  --backend-store-uri $MLFLOW_BACKEND                 --default-artifact-root $MLFLOW_ARTIFACT                 --host MLFLOW_HOST -p $MLFLOW_PORT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scanflow import tools\n",
    "\n",
    "template = tools.dockerfile_tracker()\n",
    "print(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = '/home/guess/Music/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(path_test, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container: 9eb7e6a972>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "container = client.containers.get('modeling')\n",
    "container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.765\n",
      "modeling.py:61: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  y_train.to_csv('y_train.csv', index=False)\n",
      "modeling.py:64: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  y_test.to_csv('y_test.csv', index=False)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# result = container.exec_run(cmd=f\"cd workflow; python workflow/modeling\")\n",
    "result = container.exec_run(cmd=f\"python modeling.py\", workdir='/app/workflow')\n",
    "print(result.output.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~/Desktop/scanflow/examples/leaf_ds_compose/workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scanflow.setup import setup\n",
    "from scanflow.run import run\n",
    "\n",
    "# App folder\n",
    "app_dir = '/home/guess/Desktop/scanflow/examples/leaf_ds_compose'\n",
    "\n",
    "# Workflows\n",
    "workflow1 = [\n",
    "    {'name': 'gathering_1', 'file': 'gathering.py', \n",
    "            'env': 'gathering_1'},\n",
    "    \n",
    "    {'name': 'preprocessing_1', 'file': 'preprocessing.py', \n",
    "            'env': 'preprocessing_1'}, \n",
    "\n",
    "]\n",
    "workflow2 = [\n",
    "    {'name': 'modeling_1', 'file': 'modeling.py', \n",
    "            'env': 'modeling_1'}, \n",
    "    \n",
    "    \n",
    "]\n",
    "workflows = [\n",
    "    {'name': 'workflow1', 'workflow': workflow1, 'tracker': {'port': 8001}},\n",
    "    {'name': 'workflow2', 'workflow': workflow2, 'tracker': {'port': 8002}}\n",
    "   \n",
    "]\n",
    "\n",
    "workflow_datascience = setup.Setup(app_dir, workflows)\n",
    "\n",
    "\n",
    "# Read the platform\n",
    "runner = run.Run(workflow_datascience)\n",
    "\n",
    "# Run the workflow\n",
    "runner.run_workflows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker-compose -f docker-compose.yml up -d; python main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating docker compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scanflow.setup import setup\n",
    "\n",
    "# App folder\n",
    "app_dir = '/home/guess/Desktop/scanflow/examples/demo1/data_science/'\n",
    "\n",
    "# Workflows\n",
    "workflow1 = [\n",
    "    {'name': 'gathering', 'file': 'gathering.py', \n",
    "            'dockerfile': 'Dockerfile_gathering'}, # Provides a dockerfile\n",
    "    \n",
    "    {'name': 'preprocessing', 'file': 'preprocessing.py', \n",
    "            'requirements': 'req_preprocessing.txt'}, # Convert requirements.txt to dockerfile\n",
    "\n",
    "]\n",
    "workflow2 = [\n",
    "    {'name': 'modeling', 'file': 'modeling.py', \n",
    "            'requirements': 'req_modeling.txt'}, # Convert requirements.txt to dockerfile\n",
    "    \n",
    "    \n",
    "]\n",
    "workflows = [\n",
    "    {'name': 'workflow1', 'workflow': workflow1, 'tracker': {'port': 8001}},\n",
    "    {'name': 'workflow2', 'workflow': workflow2, 'tracker': {'port': 8002}}\n",
    "   \n",
    "]\n",
    "\n",
    "# workflow_datascience = setup.Setup(app_dir, workflows)\n",
    "\n",
    "# workflow_datascience.build_workflows()\n",
    "# workflow_datascience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'workflow1',\n",
       "  'workflow': [{'name': 'gathering',\n",
       "    'file': 'gathering.py',\n",
       "    'dockerfile': 'Dockerfile_gathering'},\n",
       "   {'name': 'preprocessing',\n",
       "    'file': 'preprocessing.py',\n",
       "    'requirements': 'req_preprocessing.txt'}],\n",
       "  'tracker': {'port': 8001}},\n",
       " {'name': 'workflow2',\n",
       "  'workflow': [{'name': 'modeling',\n",
       "    'file': 'modeling.py',\n",
       "    'requirements': 'req_modeling.txt'}],\n",
       "  'tracker': {'port': 8002}}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20191216081012'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version: '3'\n",
      "services:\n",
      "  gathering:\n",
      "    image: gathering\n",
      "    container_name: gathering_20191217123736\n",
      "    networks: network_workflow1\n",
      "    depends_on: tracker_workflow1\n",
      "    environment:\n",
      "      MLFLOW_TRACKING_URI: http://tracker_workflow1:8001\n",
      "    volumes:\n",
      "    - /home/guess/Desktop/scanflow/examples/demo1/data_science/:/app\n",
      "    - /home/guess/Desktop/scanflow/examples/demo1/data_science/tracker_workflow1:/mlflow\n",
      "    tty: 'true'\n",
      "  preprocessing:\n",
      "    image: preprocessing\n",
      "    container_name: preprocessing_20191217123736\n",
      "    networks: network_workflow1\n",
      "    depends_on: tracker_workflow1\n",
      "    environment:\n",
      "      MLFLOW_TRACKING_URI: http://tracker_workflow1:8001\n",
      "    volumes:\n",
      "    - /home/guess/Desktop/scanflow/examples/demo1/data_science/:/app\n",
      "    - /home/guess/Desktop/scanflow/examples/demo1/data_science/tracker_workflow1:/mlflow\n",
      "    tty: 'true'\n",
      "  modeling:\n",
      "    image: modeling\n",
      "    container_name: modeling_20191217123736\n",
      "    networks: network_workflow2\n",
      "    depends_on: tracker_workflow2\n",
      "    environment:\n",
      "      MLFLOW_TRACKING_URI: http://tracker_workflow2:8002\n",
      "    volumes:\n",
      "    - /home/guess/Desktop/scanflow/examples/demo1/data_science/:/app\n",
      "    - /home/guess/Desktop/scanflow/examples/demo1/data_science/tracker_workflow2:/mlflow\n",
      "    tty: 'true'\n",
      "  tracker_workflow1:\n",
      "    image: tracker_workflow1\n",
      "    container_name: tracker_workflow1_20191217123736\n",
      "    networks: network_workflow1\n",
      "    volumes: /home/guess/Desktop/scanflow/examples/demo1/data_science/tracker_workflow1:/mlflow\n",
      "    ports: 8006:8001\n",
      "  tracker_workflow2:\n",
      "    image: tracker_workflow2\n",
      "    container_name: tracker_workflow2_20191217123736\n",
      "    networks: network_workflow2\n",
      "    volumes: /home/guess/Desktop/scanflow/examples/demo1/data_science/tracker_workflow2:/mlflow\n",
      "    ports: 8007:8002\n",
      "networks:\n",
      "- network_workflow1\n",
      "- network_workflow2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import oyaml as yaml\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "mlproject = {\n",
    "    'version': '3',\n",
    "    'services': {},\n",
    "    'networks': {}\n",
    "}\n",
    "\n",
    "id_date = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "# Executors\n",
    "for workflow in workflows:\n",
    "#     mlproject_t = {'services': {}}\n",
    "    for node in workflow['workflow']:\n",
    "        tracker_dir = os.path.join(app_dir, f\"tracker_{workflow['name']}\")\n",
    "        mlproject['services'].update({\n",
    "                node['name']: {\n",
    "                    'image': node['name'],\n",
    "                    'container_name': f\"{node['name']}_{id_date}\",\n",
    "                    'networks': f\"network_{workflow['name']}\",\n",
    "                    'depends_on': f\"tracker_{workflow['name']}\",\n",
    "                    'environment': {\n",
    "                        'MLFLOW_TRACKING_URI': f\"http://tracker_{workflow['name']}:{workflow['tracker']['port']}\"\n",
    "                    },\n",
    "                    'volumes': [f\"{app_dir}:/app\", \n",
    "                                f\"{tracker_dir}:/mlflow\"],\n",
    "                    'tty': 'true'\n",
    "\n",
    "                }\n",
    "        })\n",
    "    \n",
    "# Trackers\n",
    "for workflow in workflows:\n",
    "#     mlproject_t = {'services': {}}\n",
    "    if 'tracker' in workflow.keys():\n",
    "        tracker_dir = os.path.join(app_dir, f\"tracker_{workflow['name']}\")\n",
    "        port = workflow['tracker']['port']\n",
    "        mlproject['services'].update({\n",
    "                    f\"tracker_{workflow['name']}\": {\n",
    "                        'image': f\"tracker_{workflow['name']}\",\n",
    "                        'container_name': f\"tracker_{workflow['name']}_{id_date}\",\n",
    "                        'networks': f\"network_{workflow['name']}\",\n",
    "                        'volumes': f\"{tracker_dir}:/mlflow\",\n",
    "                        'ports': f\"{port+5}:{port}\"\n",
    "\n",
    "                    }\n",
    "        })\n",
    "\n",
    "net_names = [f\"network_{workflow['name']}\" for workflow in workflows]\n",
    "mlproject['networks'] = net_names\n",
    "\n",
    "print(yaml.dump(mlproject))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['gathering', 'preprocessing', 'modeling', 'tracker_workflow1', 'tracker_workflow2'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlproject['services'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import os\n",
      "import sys\n",
      "\n",
      "path = '/home/guess/Desktop/scanflow'\n",
      "sys.path.append(path) \n",
      "\n",
      "from scanflow.setup import setup\n",
      "from scanflow.run import run\n",
      "\n",
      "# App folder\n",
      "app_dir = '/home/guess/Desktop/scanflow/examples/demo1/data_science/'\n",
      "\n",
      "# Workflows\n",
      "workflow1 = [\n",
      "    {'name': 'gathering_20191217123736', 'file': 'gathering.py', \n",
      "            'env': 'gathering'},\n",
      "\n",
      "    {'name': 'preprocessing_20191217123736', 'file': 'preprocessing.py', \n",
      "            'env': 'preprocessing'}, \n",
      "\n",
      "]\n",
      "workflow2 = [\n",
      "    {'name': 'modeling_20191217123736', 'file': 'modeling.py', \n",
      "            'env': 'modeling'}, \n",
      "\n",
      "\n",
      "]\n",
      "workflows = [\n",
      "    {'name': 'workflow1', 'workflow': workflow1, 'tracker': {'port': 8001}},\n",
      "    {'name': 'workflow2', 'workflow': workflow2, 'tracker': {'port': 8002}}\n",
      "\n",
      "]\n",
      "\n",
      "workflow_datascience = setup.Setup(app_dir, workflows)\n",
      "\n",
      "\n",
      "# Read the platform\n",
      "runner = run.Run(workflow_datascience)\n",
      "\n",
      "# Run the workflow\n",
      "runner.run_workflows()\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from textwrap import dedent\n",
    "\n",
    "# def generate_main_file(app_dir, id_date):\n",
    "def generate_main_file(app_dir, id_date):\n",
    "    \n",
    "    main_file = dedent(f\"\"\"\n",
    "    import os\n",
    "    import sys\n",
    "\n",
    "    path = '/home/guess/Desktop/scanflow'\n",
    "    sys.path.append(path) \n",
    "\n",
    "    from scanflow.setup import setup\n",
    "    from scanflow.run import run\n",
    "\n",
    "    # App folder\n",
    "    app_dir = '{app_dir}'\n",
    "\n",
    "    # Workflows\n",
    "    workflow1 = [\n",
    "        {{'name': 'gathering_{id_date}', 'file': 'gathering.py', \n",
    "                'env': 'gathering'}},\n",
    "\n",
    "        {{'name': 'preprocessing_{id_date}', 'file': 'preprocessing.py', \n",
    "                'env': 'preprocessing'}}, \n",
    "\n",
    "    ]\n",
    "    workflow2 = [\n",
    "        {{'name': 'modeling_{id_date}', 'file': 'modeling.py', \n",
    "                'env': 'modeling'}}, \n",
    "\n",
    "\n",
    "    ]\n",
    "    workflows = [\n",
    "        {{'name': 'workflow1', 'workflow': workflow1, 'tracker': {{'port': 8001}}}},\n",
    "        {{'name': 'workflow2', 'workflow': workflow2, 'tracker': {{'port': 8002}}}}\n",
    "\n",
    "    ]\n",
    "\n",
    "    workflow_datascience = setup.Setup(app_dir, workflows)\n",
    "\n",
    "\n",
    "    # Read the platform\n",
    "    runner = run.Run(workflow_datascience)\n",
    "\n",
    "    # Run the workflow\n",
    "    runner.run_workflows()\n",
    "\n",
    "    \"\"\")\n",
    "    \n",
    "    return main_file\n",
    "\n",
    "print(generate_main_file(app_dir, id_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save scanflow stuff: ad_stuff\n",
    "\n",
    "- save metadata: ad_meta\n",
    "    - docker_compose: docker-compose.yml\n",
    "    - docker compose with dockerfiles: docker-compose.yml, dockerfiles\n",
    "    - docker swarm: docker-stack.yml\n",
    "    \n",
    "- save tracker: ad_tracker\n",
    "    - tracker1: mlruns\n",
    "    - tracker2: mlruns\n",
    "   \n",
    "- save checker: ad_checker\n",
    "    - data regarding checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_checker\n"
     ]
    }
   ],
   "source": [
    "! ls $ad_stuff_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "ad_stuff_dir = os.path.join(app_dir, 'ad_stuff')\n",
    "\n",
    "ad_meta_dir = os.path.join(ad_stuff_dir, 'ad_meta')\n",
    "ad_tracker_dir = os.path.join(ad_stuff_dir, 'ad_tracker')\n",
    "ad_checker_dir = os.path.join(ad_stuff_dir, 'ad_checker')\n",
    "\n",
    "os.makedirs(ad_checker_dir, exist_ok=True)\n",
    "\n",
    "# app_dir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
