{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autodeploy example with a single app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<autodeploy.setup.Setup at 0x7f7f2901f9e8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "from autodeploy import setup\n",
    "\n",
    "\n",
    "app_dir = '/home/guess/Desktop/autodeploy/examples/keras_sklearn'\n",
    "workflow = {'gathering': 'gathering.py',\n",
    "            'preprocessing': 'preprocessing.py',\n",
    "            'modeling': 'modeling.py',\n",
    "            'tuning': None,\n",
    "            'main': 'main.py'}\n",
    "\n",
    "platform = setup.Setup(app_dir, workflow)\n",
    "platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-Oct-19 09:15:52 - Pipeline: build() and run() are running.\n",
      "01-Oct-19 09:15:52 - Dockerfile was found.\n",
      "01-Oct-19 09:15:52 - Image app_single was built successfully.\n",
      "01-Oct-19 09:15:52 - MLproject was found.\n",
      "01-Oct-19 09:15:53 - Image app_single is running as app_single container.\n",
      "01-Oct-19 09:15:53 - MLflow server is running at 0.0.0.0:8001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autodeploy.setup.Setup at 0x7f7f2901f9e8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platform.pipeline()\n",
    "platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-Oct-19 09:15:15 - Container app_single was stopped.\n",
      "01-Oct-19 09:15:15 - Stopped containers were deleted.\n"
     ]
    }
   ],
   "source": [
    "# platform.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-Oct-19 09:15:58 - Pipeline: run_workflow() and deploy() are running.\n",
      "01-Oct-19 09:15:58 - Running workflow: type=single .\n",
      "01-Oct-19 09:16:03 -  Main file (main.py) output:  No matching run has been found.\n",
      "2019/10/01 07:15:59 INFO mlflow.projects: === Created directory /tmp/tmpen4w8g9t for downloading remote URIs passed to arguments of type 'path' ===\n",
      "2019/10/01 07:15:59 INFO mlflow.projects: === Running command 'python gathering.py' in run with ID 'e7229730bdea4bf88266288ab566f6fb' === \n",
      "1.2.0\n",
      "        x_1       x_2       x_3       x_4  y\n",
      "0 -1.887365 -1.145569  0.839676 -2.008856  0\n",
      "1 -0.182668 -0.122267  0.082513 -0.205466  0\n",
      "2 -0.731595  0.655904  0.205311  0.287141  0\n",
      "3 -0.774965  0.744027  0.212103  0.351875  0\n",
      "4 -1.339423 -1.042463  0.620971 -1.647999  0\n",
      "2019/10/01 07:15:59 INFO mlflow.projects: === Run (ID 'e7229730bdea4bf88266288ab566f6fb') succeeded ===\n",
      "No matching run has been found.\n",
      "2019/10/01 07:15:59 INFO mlflow.projects: === Created directory /tmp/tmpgwemvohv for downloading remote URIs passed to arguments of type 'path' ===\n",
      "2019/10/01 07:15:59 INFO mlflow.projects: === Running command 'python preprocessing.py' in run with ID '5a7dd68e4fa04836967cc8409abbea16' === \n",
      "2019/10/01 07:16:00 INFO mlflow.projects: === Run (ID '5a7dd68e4fa04836967cc8409abbea16') succeeded ===\n",
      "No matching run has been found.\n",
      "2019/10/01 07:16:01 INFO mlflow.projects: === Created directory /tmp/tmpeo89sbr7 for downloading remote URIs passed to arguments of type 'path' ===\n",
      "2019/10/01 07:16:01 INFO mlflow.projects: === Running command 'python modeling.py --source ./mlruns/0/5a7dd68e4fa04836967cc8409abbea16/artifacts/preprocessed_data.csv' in run with ID 'cdd4a88475544893900e6837612c47eb' === \n",
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py:15: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/nest.py:1286: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  _pywrap_tensorflow.RegisterType(\"Mapping\", _collections.Mapping)\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/object_identity.py:61: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  class ObjectIdentityDictionary(collections.MutableMapping):\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/keras/callbacks.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "2019-10-01 07:16:02.903884: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-10-01 07:16:02.925328: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz\n",
      "2019-10-01 07:16:02.926006: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5644d11bfc70 executing computations on platform Host. Devices:\n",
      "2019-10-01 07:16:02.926071: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-10-01 07:16:02.989027: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "Train on 6400 samples, validate on 1600 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.6724 - acc: 0.7630 - val_loss: 0.6317 - val_acc: 0.8906\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.5658 - acc: 0.8836 - val_loss: 0.4799 - val_acc: 0.8888\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.4176 - acc: 0.8805 - val_loss: 0.3532 - val_acc: 0.8894\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.3306 - acc: 0.8841 - val_loss: 0.3006 - val_acc: 0.8919\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.2941 - acc: 0.8891 - val_loss: 0.2789 - val_acc: 0.8962\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.2754 - acc: 0.8969 - val_loss: 0.2663 - val_acc: 0.9038\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.2622 - acc: 0.9038 - val_loss: 0.2567 - val_acc: 0.9119\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.2514 - acc: 0.9122 - val_loss: 0.2486 - val_acc: 0.9163\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.2422 - acc: 0.9166 - val_loss: 0.2416 - val_acc: 0.9200\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.2344 - acc: 0.9216 - val_loss: 0.2357 - val_acc: 0.9225\n",
      "The model had a ACC on the test set of 0.922\n",
      "2019/10/01 07:16:03 INFO mlflow.projects: === Run (ID 'cdd4a88475544893900e6837612c47eb') succeeded ===\n",
      "Launching new run for entrypoint=gathering and parameters={}\n",
      "Launching new run for entrypoint=preprocessing and parameters={}\n",
      "Launching new run for entrypoint=modeling and parameters={'source': './mlruns/0/5a7dd68e4fa04836967cc8409abbea16/artifacts/preprocessed_data.csv'}\n",
      " \n",
      "01-Oct-19 09:16:03 -  Workflow finished successfully. \n",
      "01-Oct-19 09:16:03 -  Deploying model as API: type=single .\n",
      "01-Oct-19 09:16:03 -  Building image: app_single_api. \n",
      "01-Oct-19 09:17:26 -  Image: app_single_api was built successfully. \n",
      "01-Oct-19 09:17:26 -  Creating container: app_single_api. \n",
      "01-Oct-19 09:17:27 -  Container: app_single_api was created successfully. \n",
      "01-Oct-19 09:17:27 -  API at: htpp://localhost:5001. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autodeploy.deploy.Deploy at 0x7f7f2875b1d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autodeploy import deploy\n",
    "\n",
    "deployer = deploy.Deploy(platform)\n",
    "\n",
    "deployer.pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "\n",
    "- Change position of mlruns\n",
    "- Add info about port deployed (50001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container in port: 5001\n",
      "Time elapsed: 0.08522868156433105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'0': 0.02475304901599884}, {'0': 0.06052611023187637}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autodeploy import track\n",
    "\n",
    "tracker = track.Track()\n",
    "\n",
    "sample_input = { \n",
    "        \"columns\": [ \n",
    "            \"x_1\", \n",
    "            \"x_2\", \n",
    "            \"x_3\", \n",
    "            \"x_4\", \n",
    "        ], \n",
    "        \"data\": [ \n",
    "            [-1.8873649,-1.1455,0.83967,-2.008855],\n",
    "            [-0.989919,  0.987401, 0.266892,  0.485329]  \n",
    "        ] \n",
    "}   \n",
    "\n",
    "predictions = tracker.predict(sample_input)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "- Show in a better way the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
